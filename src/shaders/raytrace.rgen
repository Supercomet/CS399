#version 460
#extension GL_EXT_ray_tracing : require
#extension GL_EXT_scalar_block_layout : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64  : require
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_buffer_reference2 : require
#extension GL_EXT_nonuniform_qualifier : enable

#include "shared_structs.h"

// The ray payload, attached to a ray; used to communicate between shader stages.
layout(location=0) rayPayloadEXT RayPayload payload;

// Push constant for ray tracing shaders
layout(push_constant) uniform _PushConstantRay { PushConstantRay pcRay; };

// Ray tracing descriptor set: 0:acceleration structure, and 1: color output image
layout(set=0, binding=0) uniform accelerationStructureEXT topLevelAS;
layout(set=0, binding=1, rgba32f) uniform image2D colCurr; // Output image: m_rtColCurrBuffer
layout(set=0, binding=2, scalar) buffer buffer_emitter{Emitter list[];} emitter;
layout(set=0, binding=3, rgba32f) uniform image2D colPrev; // Output image: eOutPrevImage
layout(set=0, binding=4, rgba32f) uniform image2D NdCurr; // Output image: eOutCurrNd 
layout(set=0, binding=5, rgba32f) uniform image2D NdPrev; // Output image: eOutPrevNd 
layout(set=0, binding=6, rgba32f) uniform image2D KdCurr; // Output image: eOutCurrKd 

// Object model descriptor set: 0: matrices, 1:object buffer addresses, 2: texture list
layout(set=1, binding=0) uniform _MatrixUniforms { MatrixUniforms mats; };
layout(set=1, binding=1, scalar) buffer ObjDesc_ { ObjDesc i[]; } objDesc;
layout(set=1, binding=2) uniform sampler2D textureSamplers[];

// Object buffered data; dereferenced from ObjDesc addresses
layout(buffer_reference, scalar) buffer Vertices {Vertex v[]; }; // Position, normals, ..
layout(buffer_reference, scalar) buffer Indices {ivec3 i[]; }; // Triangle indices
layout(buffer_reference, scalar) buffer Materials {Material m[]; }; // Array of all materials
layout(buffer_reference, scalar) buffer MatIndices {int i[]; }; // Material ID for each triangle

float pi = 3.14159;

// Generate a random unsigned int from two unsigned int values, using 16 pairs
// of rounds of the Tiny Encryption Algorithm. See Zafar, Olano, and Curtis,
// "GPU Random Numbers via the Tiny Encryption Algorithm"
uint tea(uint val0, uint val1)
{
  uint v0 = val0;
  uint v1 = val1;
  uint s0 = 0;

  for(uint n = 0; n < 16; n++)
  {
    s0 += 0x9e3779b9;
    v0 += ((v1 << 4) + 0xa341316c) ^ (v1 + s0) ^ ((v1 >> 5) + 0xc8013ea4);
    v1 += ((v0 << 4) + 0xad90777d) ^ (v0 + s0) ^ ((v0 >> 5) + 0x7e95761e);
  }

  return v0;
}

// Generate a random unsigned int in [0, 2^24) given the previous RNG state
// using the Numerical Recipes linear congruential generator
uint lcg(inout uint prev)
{
    uint LCG_A = 1664525u;
    uint LCG_C = 1013904223u;
    prev       = (LCG_A * prev + LCG_C);
    return prev & 0x00FFFFFF;
}

// Generate a random float in [0, 1) given the previous RNG state
float rnd(inout uint prev)
{
    return (float(lcg(prev)) / float(0x01000000));
}

// Returns a vector around A, at a "polar" angle cos=cTheta, and an "equatorial" angle Phi
vec3 SampleLobe(vec3 A, float cTheta, float Phi)
{
    float sTheta = sqrt(1 - cTheta*cTheta); // Sine of Theta
    vec3 K = vec3(sTheta*cos(Phi), sTheta*sin(Phi), cTheta); // Vector centered on Z instead of A


    // Form coordinate frame around A
    if (abs(A.z-1.0) < 1e-3) return K;
    if (abs(A.z+1.0) < 1e-3) return vec3(K[0], -K[1], -K[2]);
    vec3 B = normalize(vec3(-A[1], A[0], 0.0)); // Z x A
    vec3 C = cross(A,B);
    
    // Rotate Z to A, taking K along with
    return K[0]*B + K[1]*C + K[2]*A;
}


float approx_tan(vec3 V, vec3 N)
{
    float VN = dot(V,N);
    return sqrt( 1.0-pow(VN,2) )/VN;
}
float G_GGX(vec3 V, vec3 M , float a)
{
    float alphaG = sqrt(2.0/ (a+2));
    float vTan = approx_tan(V,M);

    return 2.0/ (1.0+ sqrt(1+alphaG*alphaG*vTan*vTan));
}
float D_GGX(vec3 N, vec3 H , float alpha)
{
    float alphaG = sqrt(2.0/ (alpha+2));
    float aGaG = pow(alphaG,2);
    float invAG = pow(alphaG-1.0,2);
    float NdotH = dot(N,H);

    return aGaG / (pi*pow( NdotH*NdotH*(aGaG-1.0) + 1.0  , 2));
}
vec3 GGXBRDF(vec3 L ,vec3 V , vec3 H , vec3 N , float alpha , vec3 Kd , vec3 Ks)
{
    float LH = dot(L,H);
    
    float D = D_GGX(N,H,alpha);
    vec3 F = Ks + (1.0-Ks) * pow(1-LH,5);
    float G = G_GGX(L,H,alpha) * G_GGX(V,H,alpha);
    
    return Kd/pi + D*F/4.0 * G;
}

// returns full  NL*(Kd/pi+F*G*D/den);  or diffuse only NL*(Kd/pi) lighting calc.
vec3 EvalBrdf(vec3 N, vec3 L, vec3 V, Material mat) 
{
    const float alpha = mat.shininess;
    float NL = max(dot(N,L),0.0);
    vec3 H = normalize(L+V);
    vec3 Kd = mat.diffuse;
    vec3 Ks = mat.specular;
    return NL * GGXBRDF(L,V,H,N,alpha,Kd,Ks);
}

// Sample a cosine log around the N direction;
// Later, get smart about specular directions.
vec3 SampleBrdf(inout uint seed, in vec3 N) 
{
    return SampleLobe(N, sqrt(rnd(seed)), 2*pi *rnd(seed));
}

// The probability distribution of the SampleBrdf function.
float PdfBrdf(vec3 N, vec3 Wi) 
{
    return dot(N, Wi)/pi;
}

Emitter SampleLight(inout uint seed)
{
     uint i = lcg(seed) % emitter.list.length();
     return emitter.list[i];
}

vec3 SampleTriangle(vec3 A, vec3 B ,vec3 C, inout uint seed)
{
    float b1 = rnd(seed);
    float b2 = rnd(seed);
    float b0 = 1-b1-b2;
    if(b0 < 0)
    {
        b1 = 1-b1;
        b2 = 1-b2;
        b0 = 1 - b1 -b2;
    }
    return b0*A + b1*B +b2*C;
}

float PdfLight(Emitter L)
{
    return 1.0/(L.area * emitter.list.length());
}

float GeometryFactor(vec3 Pa, vec3 Na, vec3 Pb, vec3 Nb)
{
    vec3 D = Pa-Pb;
    return abs( dot(D,Na) * dot(D,Nb) / pow(dot(D,D),2) );
}

vec3 EvalLight(Emitter L)
{
    return L.emission;
}

void accumulateSample(vec3 firstNorm, float firstDepth, // Projected point’s normal and depth
 ivec2 loc, // The pixel’s location (one of the four)
 float bilinearWeight, // The pixel’s bilinear weight
 inout vec4 sumC, inout float sumW // To receive the accumulated values
 )
 {
   vec4 col = imageLoad( colPrev,loc);
   vec4 Nd = imageLoad(NdPrev,loc); 
   float w = bilinearWeight;

   if(dot(firstNorm,Nd.xyz) < pcRay.n_threshold) w = 0.0;
  
   if(abs(firstDepth - Nd.w) > pcRay.d_threshold) w = 0.0;

   sumC += w*col;
   sumW += w;
 }

void main() 
{
    payload.seed = tea(gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x + gl_LaunchIDEXT.x, pcRay.frameSeed);

    // This invocation is for a pixel indicated by gl_LaunchIDEXT
    const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5);
    vec2 pixelNDC = pixelCenter/vec2(gl_LaunchSizeEXT.xy)*2.0 - 1.0;
 
    vec3 eyeW    = (mats.viewInverse * vec4(0, 0, 0, 1)).xyz;
    vec4 pixelH = mats.viewInverse * mats.projInverse * vec4(pixelNDC.x, pixelNDC.y, 1, 1);
    vec3 pixelW = pixelH.xyz/pixelH.w;
    
    vec3 rayO    = eyeW;
    vec3 rayD = normalize(pixelW - eyeW);
    payload.hit = false;

    // @@  Most of the ray casting code goes in a loop:
    // Accumulate color in a vec3 C initialized to (0,0,0)
    // Accumulate product of f/p weights in vec3 W initialized to (1,1,1)
    vec3 C = vec3(0.0,0.0,0.0);
    vec3 W = vec3(1.0,1.0,1.0);

    vec3 firstPos;
    vec3 firstCol;
    vec3 firstNorm;
    float firstDepth;


    for (int i=0; i<pcRay.depth;  i++) {
        // Fire the ray;  hit or miss shaders will be invoked, passing results back in the payload
        traceRayEXT(topLevelAS,           // acceleration structure
                    gl_RayFlagsOpaqueEXT, // rayFlags
                    0xFF,                 // cullMask
                    0,                    // sbtRecordOffset
                    0,                    // sbtRecordStride
                    0,                    // missIndex
                    rayO,                 // ray origin
                    0.001,                // ray min range
                    rayD,                 // ray direction
                    10000.0,              // ray max range
                    0                     // payload (location = 0)
                    );
                 
        // If nothing was hit, output background color.
        if (!payload.hit) {
            break; }

        // If something was hit, find the object data.
        // Object data (containing 4 device addresses)
        ObjDesc    objResources = objDesc.i[payload.instanceIndex];
    
        // Dereference the object's 4 device addresses
        Vertices   vertices    = Vertices(objResources.vertexAddress);
        Indices    indices     = Indices(objResources.indexAddress);
        Materials  materials   = Materials(objResources.materialAddress);
        MatIndices matIndices  = MatIndices(objResources.materialIndexAddress);
  
        // Use gl_PrimitiveID to access the triangle's vertices and material
        ivec3 ind    = indices.i[payload.primitiveIndex]; // The triangle hit
        int matIdx   = matIndices.i[payload.primitiveIndex]; // The triangles material index
        Material mat = materials.m[matIdx]; // The triangles material

       

        
        // If material indicates triangle is a light, pass the light's
        // emission through all BRDFs to output to a  pixel.
        
        // Vertex of the triangle (Vertex has pos, nrm, tex)
        Vertex v0 = vertices.v[ind.x];
        Vertex v1 = vertices.v[ind.y];
        Vertex v2 = vertices.v[ind.z];

        // Computing the normal and tex coord at hit position
        const vec3 bc = payload.bc; // The barycentric coordinates of the hit point
        const vec3 nrm  = bc.x*v0.nrm      + bc.y*v1.nrm      + bc.z*v2.nrm;
        const vec2 uv =  bc.x*v0.texCoord + bc.y*v1.texCoord + bc.z*v2.texCoord;

           // If the material has a texture, read diffuse color from it.
        if (mat.textureId >= 0) 
        {
            uint txtId = objResources.txtOffset + mat.textureId;
            mat.diffuse = texture(textureSamplers[(txtId)], uv).xyz; 
        }

        if(i== 0)
        {
            firstPos = payload.hitPos;
            firstNorm =  normalize(nrm);
            if(dot(firstNorm,firstNorm) == 0.0){
            imageStore(colCurr, ivec2(gl_LaunchIDEXT.xy),vec4(100.0,0.0,0.0,1.0));
            return;            }
            firstCol = mat.diffuse;
            firstDepth = payload.depth;
        }

       // image. Better yet, include a GUI slider to adjust exposure.
        if (dot(mat.emission,mat.emission) > 0.0) 
        {
            C +=  (pcRay.ExplicitLightRays? 0.5 :1.0) * ( W*mat.emission ); 
            break; 
        }

        // From the current hit point, setup N,L,V for BRDF calculation
        vec3 P = payload.hitPos;  // Current hit point

        vec3 Wi; 
        if(pcRay.ExplicitLightRays)
        {
            Emitter lightInfo = SampleLight(payload.seed);
            vec3 lightPoint = SampleTriangle(lightInfo.v0,lightInfo.v1,lightInfo.v2, payload.seed);
            Wi = normalize(lightPoint - payload.hitPos);
            float dist = length(lightPoint- payload.hitPos);
            payload.occluded = true;

            traceRayEXT(topLevelAS,
                gl_RayFlagsOpaqueEXT
                |gl_RayFlagsTerminateOnFirstHitEXT
                |gl_RayFlagsSkipClosestHitShaderEXT, // ray flags
                0xFF, // cull mask
                0, // sbtRecordoffset
                0, // sbtRecordStride
                1, // sbtmissindex
                payload.hitPos, // ray origin
                0.001, // ray min range
                Wi,         // ray direction
                dist-0.001, // ray max range
                0           // payload location
                );

            if(!payload.occluded)
            {
                vec3 N = normalize(nrm);  // Its normal
                vec3 Wo = -rayD;
                vec3 f = EvalBrdf(N, Wi, Wo, mat);                    
                float p = PdfLight(lightInfo)/GeometryFactor(payload.hitPos,N
                                                            ,lightPoint,lightInfo.normal);
               
                C += 0.5 * W * f/p * EvalLight(lightInfo);
            }
        }// end explicit lights

        
        vec3 N = normalize(nrm);  // Its normal
        Wi = SampleBrdf(payload.seed, N);
        vec3 Wo = -rayD;
        
        // Color via a BRDF calculation
        vec3 f = EvalBrdf(N, Wi, Wo, mat);        
        float p = PdfBrdf(N,Wi)*pcRay.rr;
        
        if (p != 0.0)
            W *= f/p;// Monte-Carlo

        // Step forward: Set the next ray's origin and direction to
        // current point P, and the next sample direction Wi.
        rayO = P;
        rayD = Wi;
    }

    vec4 screenH = (mats.priorViewProj * vec4(firstPos,1.0)); // project to prev buffers
    vec2 screen  = ((screenH.xy/screenH.w)+vec2(1.0)) /2.0; // H-division and map to [0,1]

    vec4 oldAve =vec4(0.0,0.0,0.0,0.0);
    float oldN = 0.0;

    //oldAve = imageLoad(colCurr,ivec2(gl_LaunchIDEXT.xy));
    //oldN = oldAve.w;
    // If first... values were not defined, OR were defined but off-screen in Prev buffers:
    if(dot(firstPos,firstPos) == 0.0
    || screen.x < 0 || screen.x >1
    || screen.y < 0 || screen.y >1)
    {
        // restart pixels accumulations
        oldN = 0.0;
        oldAve= vec4(0.0,0.0,0.0,0.0);
    }
    else
    {
        vec2 floc = screen * gl_LaunchSizeEXT.xy - vec2(0.5);
        vec2 off = fract(floc); // offset of current pixel between 4 neighbours
        ivec2 iloc = ivec2(floc); // (0,0) corner of the foor neighbours
        // the four neighbouring pixels are iloc+(0,0), +(1,0), +(0,1)+ (1,1)
        
        vec4 sumC = vec4(0.0);
        float sumW = 0;

        // Standard notation for the bilinear weights used in 4th parameter below
        float x0 = 1.0-off.x, x1 = off.x, y0 = 1.0-off.y, y1 = off.y;

        accumulateSample(firstNorm,firstDepth,iloc+ivec2(0,0),x0*y0,sumC,sumW);
        accumulateSample(firstNorm,firstDepth,iloc+ivec2(1,0),x1*y0,sumC,sumW);
        accumulateSample(firstNorm,firstDepth,iloc+ivec2(0,1),x0*y1,sumC,sumW);
        accumulateSample(firstNorm,firstDepth,iloc+ivec2(1,1),x1*y1,sumC,sumW);

        if(sumW == 0.0)
        {
           oldN = 0.0;
           oldAve = vec4(0.0);
        }
        else
        {
            vec4 history = sumC/sumW;
            oldN = history.w;
            oldAve.rgb = history.rgb;
        }
    }

    // @@Read, accumulate and write the value C into the proper image pixel
    // (oldAve,oldN) = imageLoad(colCurr, ivec2(gl_LaunchIDEXT.xy));
    //vec4 oldAve = imageLoad(colCurr,ivec2(gl_LaunchIDEXT.xy));
    float newN = oldN + 1.0;
    vec4 newAve = vec4(oldAve.rgb + (C-oldAve.rgb)/ newN, newN );
    
    if(pcRay.moved == int(true)){
     newAve = vec4(0.0,0.0,0.0,0.0);
    }
    // @@ If the camera has moved, restart accumulation by setting (oldAve,oldN) to (0,0,0, 0)
    if(any(isnan(newAve)) == false)
    {
        imageStore(colCurr, ivec2(gl_LaunchIDEXT.xy),newAve);
    }
    if(any(isnan(firstCol)) == false)
    {
         imageStore(KdCurr,  ivec2(gl_LaunchIDEXT.xy),vec4(firstCol, 0.0));
    }
    if(any(isnan(firstNorm)) == false)
    {
         imageStore(NdCurr,  ivec2(gl_LaunchIDEXT.xy),vec4(firstNorm,firstDepth));   
    }

    // Recognize camera motion at "spin +=" in camera.cpp or "myCamera.eye +=" in app.cpp
    // Communicate the camera modified state via a m_pcRay variable.
}
